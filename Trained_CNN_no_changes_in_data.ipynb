{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "Trained_CNN_no_changes_in_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurmaaan/MedNN/blob/master/Trained_CNN_no_changes_in_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEJS0vEN4wPd",
        "colab_type": "text"
      },
      "source": [
        "## Подключение Google диска"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSKOVXptBq25",
        "colab_type": "code",
        "outputId": "479f7102-3b1f-46a2-e2d7-32e749f33008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUugUbMVB0CA",
        "colab_type": "code",
        "outputId": "60da12f1-a0fc-4b26-8bd4-70b871233bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /gdrive/My\\ Drive/MedNN"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/MedNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "HjCcqIVwXwrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import models\n",
        "\n",
        "# general\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqZ30s0dXwrV",
        "colab_type": "text"
      },
      "source": [
        "## Загрузка данных "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4MhmIiHzs_8",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Параметры загрузчика\n",
        "\n",
        "batch_size = 24  #@param {type: \"slider\", min: 4, max: 128}\n",
        "\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "resize_s = 256  #@param {type: \"number\"}\n",
        "crop_s = 224  #@param {type: \"number\"}\n",
        "\n",
        "train_path = \"img/train\" #@param [\"img/train\", \"img/train_65\", \"img/train_enriched\"] {allow-input: true}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "uT0sNEeEXwre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_transforms(resize = 256, center_crop = 224):\n",
        "    tr_dict = {\n",
        "        'train': \n",
        "        [\n",
        "            transforms.Resize(resize),\n",
        "            transforms.CenterCrop(center_crop),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ],\n",
        "        'valid': \n",
        "        [\n",
        "            transforms.Resize(resize),\n",
        "            transforms.CenterCrop(center_crop),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ],\n",
        "        'test': \n",
        "        [\n",
        "            transforms.Resize(resize),\n",
        "            transforms.CenterCrop(center_crop),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]\n",
        "    }\n",
        "    return tr_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8whFaON4JHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_data(path_dict, resize = 256, center_crop = 224, batch_size = 4):\n",
        "    data_transforms = get_transforms(resize, center_crop)\n",
        "    image_datasets = {x: ImageFolder(paths[x], transforms.Compose(data_transforms[x])) for x in paths}\n",
        "    dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in paths}\n",
        "    return data_transforms, image_datasets, dataloaders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "OvxQ6bszXwro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paths = {\n",
        "    \"train\" : train_path,\n",
        "    \"test\" : \"img/test\",\n",
        "    \"valid\" : \"img/valid\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "IOmMTUc7Xwrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transforms, image_datasets, dataloaders = update_data(paths, resize_s, crop_s, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "voEaCjiRXwr2",
        "colab_type": "code",
        "outputId": "e579f621-b935-4139-d91f-584b77b0203b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "class_names = image_datasets['train'].classes\n",
        "class_names"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['actinic keratosis',\n",
              " 'basal cell carcinoma',\n",
              " 'dermatofibroma',\n",
              " 'melanoma',\n",
              " 'nevus',\n",
              " 'pigmented benign keratosis',\n",
              " 'squamous cell carcinoma',\n",
              " 'vascular lesion']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTuQxQO05rPd",
        "colab_type": "text"
      },
      "source": [
        "TODO: проверить как веса в data loader будут влиять на качество"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "qlGCVudHXwr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# target = torch.tensor(image_datasets[\"train\"].targets)\n",
        "# class_sample_count = torch.tensor([(target == t).sum() for t in torch.unique(target, sorted=True)])\n",
        "# weight = 1. / class_sample_count.float()\n",
        "# samples_weight = torch.tensor([weight[t] for t in target])\n",
        "\n",
        "# sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "# dataloaders[\"train\"] = DataLoader(image_datasets[\"train\"], batch_size=batch_size, num_workers=4, sampler=sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "kpPSTWQbXwsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_sizes = {x: len(image_datasets[x]) for x in paths}\n",
        "for p in dataset_sizes:\n",
        "    if dataset_sizes[p] % batch_size == 1:\n",
        "        print(f\"Incorrect bath_size. {p} size % batch_size = {dataset_sizes[p]} % {batch_size} == 1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "RBRDvQHzXwsb",
        "colab_type": "code",
        "outputId": "3cb20568-032f-4397-ea09-ea7b0de40c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "class_counts = defaultdict(dict)\n",
        "for p in paths:\n",
        "    for cl in class_names:\n",
        "        class_counts[p][cl] = len(os.listdir(f\"{paths[p]}/{cl}\"))\n",
        "pd.DataFrame(class_counts)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>test</th>\n",
              "      <th>valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>actinic keratosis</th>\n",
              "      <td>71</td>\n",
              "      <td>30</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>basal cell carcinoma</th>\n",
              "      <td>297</td>\n",
              "      <td>127</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dermatofibroma</th>\n",
              "      <td>65</td>\n",
              "      <td>28</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>melanoma</th>\n",
              "      <td>608</td>\n",
              "      <td>303</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nevus</th>\n",
              "      <td>3760</td>\n",
              "      <td>1673</td>\n",
              "      <td>1272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pigmented benign keratosis</th>\n",
              "      <td>632</td>\n",
              "      <td>259</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>squamous cell carcinoma</th>\n",
              "      <td>120</td>\n",
              "      <td>47</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vascular lesion</th>\n",
              "      <td>80</td>\n",
              "      <td>37</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            train  test  valid\n",
              "actinic keratosis              71    30     29\n",
              "basal cell carcinoma          297   127     90\n",
              "dermatofibroma                 65    28     22\n",
              "melanoma                      608   303    202\n",
              "nevus                        3760  1673   1272\n",
              "pigmented benign keratosis    632   259    208\n",
              "squamous cell carcinoma       120    47     30\n",
              "vascular lesion                80    37     25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAIFfx5FXwsg",
        "colab_type": "text"
      },
      "source": [
        "## Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "tjQfaXmAXwsg",
        "colab_type": "code",
        "outputId": "3728fab4-5da3-4c15-bd86-60edf7382b27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"CPU device\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqAO-fFXXwsk",
        "colab_type": "text"
      },
      "source": [
        "## Визуализация "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "OOsuAg7TXwsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    \n",
        "    #revert normalization\n",
        "    inp = std * inp + mean\n",
        "    \n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.figure(figsize=(16, 16))\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "Oqp4_cmtXwsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs, labels = next(iter(dataloaders['train']))\n",
        "\n",
        "out = torchvision.utils.make_grid(imgs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in labels])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G3-Ot3BvXwsq",
        "colab_type": "text"
      },
      "source": [
        "## Функция обучения\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "myBeud6JXwsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler = None, num_epochs=25):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    stat_dict = {\n",
        "        \"train\" :{ \"epoch\" : [], \"loss\" : [], \"acc\" : [] },\n",
        "        \"valid\" :{ \"epoch\" : [], \"loss\" : [], \"acc\" : [] }\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        estart_time = time.time()\n",
        "        # У каждой эпохи есть фаза обучения и фаза валидации \n",
        "        for phase in [\"train\", \"valid\"]:\n",
        "            is_train_phase = (phase == \"train\")\n",
        "            # Ставим модель в нужный режим в зависимости от фазы \n",
        "            model.train(is_train_phase)\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            \n",
        "            # Проходим по датасету партиями размером с батч\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Обнуляем градиенты вычесленные на предыдущем батче, иначе они будут складываться один за другим \n",
        "                optimizer.zero_grad()\n",
        "                # Прямой проход Общая для обучения и валидации. \n",
        "                # Если фаза обучения, то все градиенты (частные производные функции потерь) \n",
        "                # будут вычислены чтобы вычесть их из текущих весов. Если валидация - вычисляться не будут\n",
        "                with torch.set_grad_enabled(is_train_phase):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    # Реализация обратного распространения ошибки \n",
        "                    if is_train_phase:\n",
        "                        # Рассчет всех частных производных dloss_dw1(w1_0). Внутри батча усредняются\n",
        "                        loss.backward()\n",
        "                        # обновление весов (w1_1 = w1_0 - lr * dloss_dw1(w1_0) и так далее\n",
        "                        optimizer.step() \n",
        "\n",
        "                # statistics inputs.size(0) = batch_size \n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "            if is_train_phase and (scheduler is not None):\n",
        "                scheduler.step()\n",
        "            \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            \n",
        "            stat_dict[phase][\"epoch\"].append(epoch)\n",
        "            stat_dict[phase][\"loss\"].append(epoch_loss)\n",
        "            stat_dict[phase][\"acc\"].append(epoch_acc.item())\n",
        "            \n",
        "            te = time.time() - estart_time\n",
        "            print(f\"Эпоха {epoch + 1}/{num_epochs}. {phase}. loss: {epoch_loss : .4f}. acc: {epoch_acc : .4f}. Время {te // 60 : .0f}м {te % 60 : .0f}с\")\n",
        "                \n",
        "            # deep copy the model\n",
        "            if (not is_train_phase) and (epoch_acc > best_acc):\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    time_elapsed = time.time() - start_time\n",
        "    print(f\"Обучение закончено. Общее время: {time_elapsed // 60 : .0f}м {time_elapsed % 60 : .0f}с\")\n",
        "    print(f\"Лучший valid acc: {best_acc : .4f}\")\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, stat_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMFal4hoXwss",
        "colab_type": "text"
      },
      "source": [
        "## Функция тестирования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "ToLAyAOwXwst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, print_log=True):\n",
        "    start_time = time.time()\n",
        "    result_dict = { \"real\" : [], \"predicted\" : [] }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloaders[\"test\"]:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            for i in range(len(labels)):\n",
        "                result_dict[\"real\"].append(class_names[labels[i]])\n",
        "                result_dict[\"predicted\"].append(class_names[predicted[i]])\n",
        "\n",
        "    result_df = pd.DataFrame(result_dict)\n",
        "\n",
        "    acc_dict = {}\n",
        "    total_acc = accuracy_score(result_df[\"real\"], result_df[\"predicted\"]) * 100\n",
        "    acc_dict[\"total\"] = total_acc\n",
        "\n",
        "    for img_class in class_names:\n",
        "        class_df = result_df[result_df[\"real\"] == img_class]\n",
        "        class_acc = accuracy_score(class_df[\"real\"], class_df[\"predicted\"]) * 100\n",
        "        acc_dict[img_class] = class_acc\n",
        "        if print_log:\n",
        "            print(f\"{img_class} ({len(class_df)}) : {class_acc : .2f}%\")\n",
        "\n",
        "    if print_log:\n",
        "        print(f\"Общий test acc: {total_acc : .2f}%\")\n",
        "        time_elapsed = time.time() - start_time\n",
        "        print(f\"Время тестирования: {time_elapsed // 60 : .0f}м {time_elapsed % 60 : .0f}с\")\n",
        "    \n",
        "    return acc_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0wqovMjfXwsv",
        "colab_type": "text"
      },
      "source": [
        "## Вспомогательные функции "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "91aDFoqkXws0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_score_to_df(score_dict, save_flag=True, save_path = \"/nn\", save_dir=\"\", single_model=False):\n",
        "    data = defaultdict(list)\n",
        "    if len(score_dict.keys()) > 0:\n",
        "        first_model_name = list(score_dict.keys())[0]\n",
        "        for scope in score_dict[first_model_name]:\n",
        "            data[\"scope\"].append(scope)\n",
        "            for model_name in score_dict:\n",
        "                data[model_name].append(f\"{score_dict[model_name][scope] : .2f}\")\n",
        "        \n",
        "        df = pd.DataFrame(data)\n",
        "        df = df.set_index(\"scope\")\n",
        "        \n",
        "        if save_flag:\n",
        "            output_dir = f\"{save_path}/{save_dir}\"\n",
        "            if not os.path.isdir(output_dir):\n",
        "                os.makedirs(output_dir)\n",
        "            file_name = f\"{first_model_name}_score.csv\" if single_model else \"models_score.csv\"\n",
        "\n",
        "            df.to_csv(f\"{output_dir}/{file_name}\", sep=';')\n",
        "    else:\n",
        "        df  = pd.DataFrame()\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "pHiRFg5IXws3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_learning_stat(loss_dict, save_path = \"/nn\", save_dir=\"\", modelname=\"NN\"):\n",
        "    output_dir = f\"{save_path}/{save_dir}\"\n",
        "    if not os.path.isdir(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    with open(f\"{output_dir}/{modelname}.json\", 'w') as json_file:\n",
        "        json.dump(loss_dict, json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "wnpINf81XwtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_learning_curve(data, model_name, save_flag=True, save_path = \"/nn\", save_dir=\"\"):\n",
        "    # data = json.load(open(path_json, 'r'))\n",
        "    \n",
        "    epochs = data[\"train\"][\"epoch\"]\n",
        "    \n",
        "    fig, axs = plt.subplots(2, figsize=(16,12))\n",
        "    # model_name = path.split('/')[-1].split('.')[0]\n",
        "    fig.suptitle(model_name)\n",
        "    \n",
        "    epcnt = float(epochs[-1])\n",
        "    step = 1\n",
        "    while epcnt / step >= 20:\n",
        "        step += 1\n",
        "\n",
        "    for i, mode in enumerate([\"loss\", \"acc\"]):\n",
        "        for phase in [\"train\", \"valid\"]:\n",
        "            axs[i].set_title(mode)\n",
        "            axs[i].plot(epochs, data[phase][mode], label=phase)\n",
        "            axs[i].set_xlabel(\"Эпохи\")\n",
        "            axs[i].legend(loc=1)\n",
        "            axs[i].grid(True)\n",
        "            delta = 0.001\n",
        "            axs[i].set_xlim(xmin=(0 - delta), xmax=(epcnt + delta))\n",
        "            axs[i].set_xticks([xt for xt in range(0, int(epcnt+1), step)])\n",
        "\n",
        "    if save_flag:\n",
        "        output_dir = f\"{save_path}/{save_dir}\"\n",
        "        if not os.path.isdir(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "        save_learning_stat(data, save_path, save_dir, model_name)\n",
        "        plt.savefig(f\"{output_dir}/{model_name}.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGsHBhJTT1LU",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Параметры обучения\n",
        "\n",
        "save_path = \"/gdrive/My Drive/MedNN/nn\" #@param {type: \"string\"}\n",
        "save_dir = \"deftBlnc_noSamplerWts_24ep\" #@param {type: \"string\"}\n",
        "#@markdown ---\n",
        "num_epochs = 24 #@param {type:\"slider\", min:3, max:45, step:3}\n",
        "#@markdown ---\n",
        "start_lr = 0.01  #@param {type: \"number\"}\n",
        "use_lr_scheduler = True #@param {type:\"boolean\"}\n",
        "lr_scheduler_step = 8 #@param {type:\"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT_W7Ze0jdUk",
        "colab_type": "text"
      },
      "source": [
        "## **ОБУЧЕНИЕ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOQe4yeyoEaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learn_model(model, model_name, params_to_learn):\n",
        "    print('_' * 30, model_name, '_' * 30)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(params_to_learn, lr=start_lr, momentum=0.9)\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=lr_scheduler_step, gamma=0.1) if use_lr_scheduler else None\n",
        "\n",
        "    model, learning_dict = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs)\n",
        "    plot_learning_curve(learning_dict, model_name, True, save_path, save_dir)\n",
        "    coeff_path = f\"{save_path}/{save_dir}/{model_name}.pth\"\n",
        "    torch.save(model.state_dict(), coeff_path)\n",
        "    print()\n",
        "    score = test_model(model, False)\n",
        "    return convert_score_to_df({model_name : score}, True, save_path, save_dir, True)\n",
        "    # return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNwUycGQjjKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dict = {\n",
        "\t\"ResNet_152\" : {\"model\" : models.resnet152(pretrained=True), \"type\" : \"fc\"},\n",
        "\t\"AlexNet\" : {\"model\" : models.alexnet(pretrained=True), \"type\" : \"cl\"},\n",
        "\t\"VGG_19_bn\" : {\"model\" : models.vgg19_bn(pretrained=True), \"type\" : \"cl\"},\n",
        "\t\"ShuffleNet_v2_x1-0\" : {\"model\" : models.shufflenet_v2_x1_0(pretrained=True), \"type\" : \"fc\"},\n",
        "\t\"MobileNet_v2\" : {\"model\" : models.mobilenet_v2(pretrained=True), \"type\" : \"cl\"},\n",
        "\t\"MnasNet_1-0\" : {\"model\" : models.mnasnet1_0(pretrained=True), \"type\" : \"cl\"},\n",
        "\t\"ResNeXt_101_32x8d\" : {\"model\" : models.resnext101_32x8d(pretrained=True), \"type\" : \"fc\"},\n",
        "\t\"Wide_ResNet_101-2\" : {\"model\" : models.wide_resnet101_2(pretrained=True), \"type\" : \"fc\"},\n",
        "    \"Inception_v3\" : {\"model\" : models.inception_v3(pretrained=True), \"type\" : \"fc\"}\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G3nEG0Eo6L-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transforms, image_datasets, dataloaders = update_data(resize_s, crop_s, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKAU3HFRkket",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for model_name in model_dict:\n",
        "    model = model_dict[model_name][\"model\"]\n",
        "    \n",
        "    if model_name == \"Inception_v3\":\n",
        "        data_transforms, image_datasets, dataloaders = update_data(resize=340, center_crop=299, batch_size = batch_size)\n",
        "        model.aux_logits=False\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    params_to_learn = model.parameters()\n",
        "\n",
        "    if model_dict[model_name][\"type\"] == \"fc\":\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "        params_to_learn = model.fc.parameters()\n",
        "    else:\n",
        "        num_ftrs = model.classifier[-1].in_features\n",
        "        model.classifier[-1] = nn.Linear(num_ftrs, len(class_names))\n",
        "        params_to_learn = model.classifier[-1].parameters()\n",
        "    try:\n",
        "        learn_model(model, model_name, params_to_learn)\n",
        "    except Exception as e:\n",
        "        print(f\"{model_name} failed. {str(e)}\")\n",
        "\n",
        "    print('\\n', '-' * 80, '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK8O_PhIjmwh",
        "colab_type": "text"
      },
      "source": [
        "## Объединение результатов "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYOKkDf0jrcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVMXHQMHXwtQ",
        "colab_type": "text"
      },
      "source": [
        "## Предсказание"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "bQMhcHJ1XwtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(img_path=None, model_name=\"inception_v3\", path=\"/nn/default/inception_v3.pth\"):\n",
        "    if os.path.isfile(img_path) and (model_name in model_dict) and os.path.isfile(img_path):\n",
        "        img = Image.open(img_path)\n",
        "        model = model_dict[model_name]\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, 8)\n",
        "        model.load_state_dict(torch.load(path))\n",
        "        model.eval()\n",
        "        \n",
        "        img_input = transforms.Compose(data_transforms[\"test\"])(img)\n",
        "        img_input = img_input.unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            output = model(img_input)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            proba = torch.nn.functional.softmax(output, dim=1).tolist()[0]\n",
        "            \n",
        "            plt.barh(class_names, proba, align=\"center\")\n",
        "            plt.xlim(0, 1)\n",
        "            plt.xticks(np.arange(0, 1, 0.1))\n",
        "            plt.grid(True, axis=\"x\")\n",
        "            \n",
        "            for i, p in enumerate(proba):\n",
        "                print(f\"{p : .10f} - {class_names[i]}\")\n",
        "                plt.text(p, i, f\"{p : .10f}\")\n",
        "        return class_names[predicted[0]]\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}