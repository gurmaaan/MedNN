{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gurmaaan/MedNN/blob/master/Trained_CNN_no_changes_in_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OEJS0vEN4wPd"
   },
   "source": [
    "## Подключение Google диска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "QSKOVXptBq25",
    "outputId": "479f7102-3b1f-46a2-e2d7-32e749f33008"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lUugUbMVB0CA",
    "outputId": "60da12f1-a0fc-4b26-8bd4-70b871233bc4"
   },
   "outputs": [],
   "source": [
    "%cd /gdrive/My\\ Drive/MedNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HjCcqIVwXwrR",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#pytorch\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import models\n",
    "\n",
    "# general\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqZ30s0dXwrV"
   },
   "source": [
    "## Загрузка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "D4MhmIiHzs_8"
   },
   "outputs": [],
   "source": [
    "#@title Параметры загрузчика\n",
    "\n",
    "batch_size = 24  #@param {type: \"slider\", min: 4, max: 128}\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "resize_s = 256  #@param {type: \"number\"}\n",
    "crop_s = 224  #@param {type: \"number\"}\n",
    "\n",
    "train_path = \"img/train\" #@param [\"img/train\", \"img/train_65\", \"img/train_enriched\"] {allow-input: true}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uT0sNEeEXwre",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_transforms(resize = 256, center_crop = 224):\n",
    "    tr_dict = {\n",
    "        'train': \n",
    "        [\n",
    "            transforms.Resize(resize),\n",
    "            transforms.CenterCrop(center_crop),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ],\n",
    "        'valid': \n",
    "        [\n",
    "            transforms.Resize(resize),\n",
    "            transforms.CenterCrop(center_crop),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ],\n",
    "        'test': \n",
    "        [\n",
    "            transforms.Resize(resize),\n",
    "            transforms.CenterCrop(center_crop),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ]\n",
    "    }\n",
    "    return tr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8whFaON4JHp"
   },
   "outputs": [],
   "source": [
    "def update_data(path_dict, resize = 256, center_crop = 224, batch_size = 4):\n",
    "    data_transforms = get_transforms(resize, center_crop)\n",
    "    image_datasets = {x: ImageFolder(paths[x], transforms.Compose(data_transforms[x])) for x in paths}\n",
    "    dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in paths}\n",
    "    return data_transforms, image_datasets, dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OvxQ6bszXwro",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    \"train\" : train_path,\n",
    "    \"test\" : \"img/test\",\n",
    "    \"valid\" : \"img/valid\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IOmMTUc7Xwrj",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_transforms, image_datasets, dataloaders = update_data(paths, resize_s, crop_s, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 1, 4, 5, 6, 4, 4, 4, 4, 4, 4, 4, 5, 6, 5, 4, 4, 4, 4, 4, 3, 4, 7, 3])\n",
      "tensor([5, 4, 5, 4, 5, 1, 4, 4, 4, 4, 4, 3, 4, 5, 4, 4, 6, 5, 3, 4, 4, 4, 4, 4])\n",
      "tensor([6, 4, 4, 4, 4, 4, 5, 5, 4, 3, 5, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 7, 4, 4])\n",
      "tensor([5, 4, 5, 1, 4, 5, 4, 4, 5, 4, 4, 4, 1, 6, 4, 4, 7, 4, 4, 3, 4, 4, 4, 4])\n",
      "tensor([4, 1, 4, 4, 4, 4, 1, 2, 2, 4, 4, 7, 4, 5, 4, 6, 4, 4, 4, 4, 4, 5, 4, 4])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 6, 3, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([3, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 5, 3, 4, 4, 1, 4, 4])\n",
      "tensor([4, 4, 7, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 4, 5, 4, 4, 4, 4, 5, 4, 5, 4, 4])\n",
      "tensor([4, 1, 4, 4, 4, 4, 4, 4, 5, 4, 5, 5, 3, 1, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4])\n",
      "tensor([1, 4, 4, 4, 4, 4, 4, 4, 4, 5, 3, 3, 4, 1, 4, 3, 4, 4, 4, 4, 4, 5, 4, 4])\n",
      "tensor([4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 5, 3, 4, 3, 4, 4, 2, 3, 3, 4, 6, 4])\n",
      "tensor([4, 4, 4, 4, 5, 0, 4, 4, 3, 3, 5, 4, 3, 4, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4])\n",
      "tensor([4, 4, 4, 1, 1, 7, 3, 4, 4, 4, 5, 4, 4, 4, 4, 3, 3, 5, 1, 4, 4, 4, 1, 5])\n",
      "tensor([0, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 5, 5, 0, 4, 4, 4, 5, 3, 4, 6, 4, 4, 3])\n",
      "tensor([4, 3, 4, 5, 4, 1, 4, 4, 5, 5, 3, 4, 4, 6, 5, 4, 0, 4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 3, 5, 5, 4, 4, 4])\n",
      "tensor([3, 4, 6, 4, 4, 4, 1, 3, 4, 3, 4, 5, 4, 4, 4, 4, 1, 4, 3, 4, 1, 4, 4, 1])\n",
      "tensor([4, 4, 5, 3, 4, 4, 3, 4, 4, 5, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 3, 4, 4, 4])\n",
      "tensor([4, 5, 4, 4, 4, 4, 1, 4, 5, 4, 4, 4, 1, 4, 4, 4, 4, 5, 4, 4, 4, 4, 3, 4])\n",
      "tensor([4, 4, 4, 4, 1, 1, 1, 5, 4, 3, 4, 4, 5, 4, 5, 4, 3, 4, 4, 4, 4, 4, 4, 3])\n",
      "tensor([4, 4, 4, 5, 4, 4, 4, 4, 5, 7, 4, 4, 4, 0, 4, 5, 4, 4, 4, 3, 4, 4, 3, 4])\n",
      "tensor([4, 4, 5, 4, 4, 4, 4, 4, 4, 5, 5, 5, 4, 3, 4, 1, 3, 4, 5, 4, 5, 4, 7, 4])\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, labels) in enumerate(dataloaders[\"train\"]):\n",
    "    print(labels)\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "voEaCjiRXwr2",
    "outputId": "b583df50-5afe-4121-fda0-3108568c0091",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actinic keratosis',\n",
       " 'basal cell carcinoma',\n",
       " 'dermatofibroma',\n",
       " 'melanoma',\n",
       " 'nevus',\n",
       " 'pigmented benign keratosis',\n",
       " 'squamous cell carcinoma',\n",
       " 'vascular lesion']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TTuQxQO05rPd"
   },
   "source": [
    "TODO: проверить как веса в data loader будут влиять на качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlGCVudHXwr9",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# target = torch.tensor(image_datasets[\"train\"].targets)\n",
    "# class_sample_count = torch.tensor([(target == t).sum() for t in torch.unique(target, sorted=True)])\n",
    "# weight = 1. / class_sample_count.float()\n",
    "# samples_weight = torch.tensor([weight[t] for t in target])\n",
    "\n",
    "# sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "# dataloaders[\"train\"] = DataLoader(image_datasets[\"train\"], batch_size=batch_size, num_workers=4, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kpPSTWQbXwsR",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': 2504, 'train': 5633, 'valid': 1878}\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in paths}\n",
    "pprint(dataset_sizes)\n",
    "for p in dataset_sizes:\n",
    "    if dataset_sizes[p] % batch_size == 1:\n",
    "        print(f\"Incorrect bath_size. {p} size % batch_size = {dataset_sizes[p]} % {batch_size} == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "RBRDvQHzXwsb",
    "outputId": "3cb20568-032f-4397-ea09-ea7b0de40c4e",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>actinic keratosis</td>\n",
       "      <td>71</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>basal cell carcinoma</td>\n",
       "      <td>297</td>\n",
       "      <td>127</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dermatofibroma</td>\n",
       "      <td>65</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>melanoma</td>\n",
       "      <td>608</td>\n",
       "      <td>303</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nevus</td>\n",
       "      <td>3760</td>\n",
       "      <td>1673</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pigmented benign keratosis</td>\n",
       "      <td>632</td>\n",
       "      <td>259</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>squamous cell carcinoma</td>\n",
       "      <td>120</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vascular lesion</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            train  test  valid\n",
       "actinic keratosis              71    30     29\n",
       "basal cell carcinoma          297   127     90\n",
       "dermatofibroma                 65    28     22\n",
       "melanoma                      608   303    202\n",
       "nevus                        3760  1673   1272\n",
       "pigmented benign keratosis    632   259    208\n",
       "squamous cell carcinoma       120    47     30\n",
       "vascular lesion                80    37     25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = defaultdict(dict)\n",
    "for p in paths:\n",
    "    for cl in class_names:\n",
    "        class_counts[p][cl] = len(os.listdir(f\"{paths[p]}/{cl}\"))\n",
    "pd.DataFrame(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zAIFfx5FXwsg"
   },
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tjQfaXmAXwsg",
    "outputId": "3728fab4-5da3-4c15-bd86-60edf7382b27",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 970\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CPU device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oqAO-fFXXwsk"
   },
   "source": [
    "## Визуализация "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOsuAg7TXwsl",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    #revert normalization\n",
    "    inp = std * inp + mean\n",
    "    \n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "Oqp4_cmtXwsn",
    "outputId": "a4308c77-19d8-44d0-9648-abeeebd07b15",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "imgs, labels = next(iter(dataloaders['train']))\n",
    "\n",
    "out = torchvision.utils.make_grid(imgs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G3-Ot3BvXwsq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Функция обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "myBeud6JXwsr",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler = None, num_epochs=25):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    stat_dict = {\n",
    "        \"train\" :{ \"epoch\" : [], \"loss\" : [], \"acc\" : [] },\n",
    "        \"valid\" :{ \"epoch\" : [], \"loss\" : [], \"acc\" : [] }\n",
    "    }\n",
    "    expect = 0\n",
    "    print(f\"Начало обучения. Проход в {num_epochs} эпох.\")\n",
    "    for epoch in range(num_epochs):\n",
    "        estart_time = time.time()\n",
    "        # У каждой эпохи есть фаза обучения и фаза валидации \n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            is_train_phase = (phase == \"train\")\n",
    "            # Ставим модель в нужный режим в зависимости от фазы \n",
    "            model.train(is_train_phase)\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Проходим по датасету партиями размером с батч\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Обнуляем градиенты вычесленные на предыдущем батче, иначе они будут складываться один за другим \n",
    "                optimizer.zero_grad()\n",
    "                # Прямой проход Общая для обучения и валидации. \n",
    "                # Если фаза обучения, то все градиенты (частные производные функции потерь) \n",
    "                # будут вычислены чтобы вычесть их из текущих весов. Если валидация - вычисляться не будут\n",
    "                with torch.set_grad_enabled(is_train_phase):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # Реализация обратного распространения ошибки \n",
    "                    if is_train_phase:\n",
    "                        # Рассчет всех частных производных dloss_dw1(w1_0). Внутри батча усредняются\n",
    "                        loss.backward()\n",
    "                        # Обновление весов (w1_1 = w1_0 - lr * dloss_dw1(w1_0) и так далее\n",
    "                        optimizer.step() \n",
    "\n",
    "                # Расчет точности и потери на конкретной эпохе \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if is_train_phase and (scheduler is not None):\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            # Сохраняем веса если точность выше чем была\n",
    "            if (not is_train_phase) and (epoch_acc > best_acc):\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            stat_dict[phase][\"epoch\"].append(epoch)\n",
    "            stat_dict[phase][\"loss\"].append(epoch_loss)\n",
    "            stat_dict[phase][\"acc\"].append(epoch_acc.item())\n",
    "            \n",
    "            te = time.time() - estart_time\n",
    "            if epoch == 0:\n",
    "                expect += te\n",
    "                if not is_train_phase:\n",
    "                    expect *= (num_epochs - 1) * 0.6\n",
    "                    print(f\"{datetime.now():%Y-%m-%d %H:%M}. Приблизительное оставшееся время {expect//60:2.0f}м {expect%60:2.0f}с\")\n",
    "                    print(\"***\")\n",
    "            if ( (epoch+1) % 5 == 0 ) and epoch != 0:        \n",
    "                print(f\"{epoch+1:2}. {phase}. loss: {epoch_loss:.4f}. acc: {epoch_acc:.4f}. time {te//60:2.0f}м {te%60:2.0f}с\")\n",
    "\n",
    "    print('-'*80)\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f\"Обучение закончено. Общее время: {time_elapsed//60:2.0f}м {time_elapsed%60:2.0f}с\")\n",
    "    print(f\"valid acc: {best_acc * 100 :.2f}%\")\n",
    "\n",
    "    # Возвращается модель с лучшими весами \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, stat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XMFal4hoXwss"
   },
   "source": [
    "## Функция тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToLAyAOwXwst",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, print_log=True):\n",
    "    result_dict = { \"real\" : [], \"predicted\" : [] }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloaders[\"test\"]:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            for i in range(len(labels)):\n",
    "                result_dict[\"real\"].append(class_names[labels[i]])\n",
    "                result_dict[\"predicted\"].append(class_names[predicted[i]])\n",
    "\n",
    "    result_df = pd.DataFrame(result_dict)\n",
    "\n",
    "    acc_dict = {}\n",
    "    total_acc = accuracy_score(result_df[\"real\"], result_df[\"predicted\"]) * 100\n",
    "    acc_dict[\"total\"] = total_acc\n",
    "\n",
    "    for img_class in class_names:\n",
    "        class_df = result_df[result_df[\"real\"] == img_class]\n",
    "        class_acc = accuracy_score(class_df[\"real\"], class_df[\"predicted\"]) * 100\n",
    "        acc_dict[img_class] = class_acc\n",
    "        if print_log:\n",
    "            print(f\"{img_class} ({len(class_df)}) : {class_acc :.2f}%\")\n",
    "\n",
    "    print(f\"test acc: {total_acc :.2f}%\")\n",
    "    \n",
    "    return acc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wqovMjfXwsv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Вспомогательные функции "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "91aDFoqkXws0",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def convert_score_to_df(score_dict, save_flag=True, save_path = \"/nn\", save_dir=\"\", single_model=False):\n",
    "    data = defaultdict(list)\n",
    "    if len(score_dict.keys()) > 0:\n",
    "        first_model_name = list(score_dict.keys())[0]\n",
    "        for scope in score_dict[first_model_name]:\n",
    "            data[\"scope\"].append(scope)\n",
    "            for model_name in score_dict:\n",
    "                data[model_name].append(f\"{score_dict[model_name][scope] : .2f}\")\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df = df.set_index(\"scope\")\n",
    "        \n",
    "        if save_flag:\n",
    "            output_dir = f\"{save_path}/{save_dir}\"\n",
    "            if not os.path.isdir(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            file_name = f\"{first_model_name}_score.csv\" if single_model else \"models_score.csv\"\n",
    "\n",
    "            df.to_csv(f\"{output_dir}/{file_name}\", sep=';')\n",
    "    else:\n",
    "        df  = pd.DataFrame()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHiRFg5IXws3",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def save_learning_stat(loss_dict, save_path = \"/nn\", save_dir=\"\", modelname=\"NN\"):\n",
    "    output_dir = f\"{save_path}/{save_dir}\"\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    with open(f\"{output_dir}/{modelname}.json\", 'w') as json_file:\n",
    "        json.dump(loss_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnpINf81XwtM",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(data, model_name, save_flag=True, save_path = \"/nn\", save_dir=\"\"):\n",
    "    # data = json.load(open(path_json, 'r'))\n",
    "    \n",
    "    epochs = data[\"train\"][\"epoch\"]\n",
    "    \n",
    "    fig, axs = plt.subplots(2, figsize=(16,12))\n",
    "    # model_name = path.split('/')[-1].split('.')[0]\n",
    "    fig.suptitle(model_name)\n",
    "    \n",
    "    epcnt = float(epochs[-1])\n",
    "    step = 1\n",
    "    while epcnt / step >= 20:\n",
    "        step += 1\n",
    "\n",
    "    for i, mode in enumerate([\"loss\", \"acc\"]):\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            axs[i].set_title(mode)\n",
    "            axs[i].plot(epochs, data[phase][mode], label=phase)\n",
    "            axs[i].set_xlabel(\"Эпохи\")\n",
    "            axs[i].legend(loc=1)\n",
    "            axs[i].grid(True)\n",
    "            delta = 0.001\n",
    "            axs[i].set_xlim(xmin=(0 - delta), xmax=(epcnt + delta))\n",
    "            axs[i].set_xticks([xt for xt in range(0, int(epcnt+1), step)])\n",
    "\n",
    "    if save_flag:\n",
    "        output_dir = f\"{save_path}/{save_dir}\"\n",
    "        if not os.path.isdir(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        save_learning_stat(data, save_path, save_dir, model_name)\n",
    "        plt.savefig(f\"{output_dir}/{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "rGsHBhJTT1LU"
   },
   "outputs": [],
   "source": [
    "#@title Параметры обучения\n",
    "\n",
    "save_path = \"C:/Users/Dima/YandexDisk/EDUCATION/_Deeplom/nn\" #@param {type: \"string\"}\n",
    "save_dir = \"layerTest_other_24ep\" #@param {type: \"string\"}\n",
    "#@markdown ---\n",
    "num_epochs = 24 #@param {type:\"slider\", min:3, max:45, step:3}\n",
    "#@markdown ---\n",
    "start_lr = 0.01  #@param {type: \"number\"}\n",
    "use_lr_scheduler = True #@param {type:\"boolean\"}\n",
    "lr_scheduler_step = 7 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KT_W7Ze0jdUk"
   },
   "source": [
    "## **ОБУЧЕНИЕ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9G3nEG0Eo6L-"
   },
   "outputs": [],
   "source": [
    "data_transforms, image_datasets, dataloaders = update_data(paths, resize_s, crop_s, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rNwUycGQjjKz"
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"ResNeXt_50_32x4d\": {\"model\" : models.resnext50_32x4d(pretrained=True), \"type\" : \"fc\", \"epochs\" : num_epochs, \"lr_step\" : lr_scheduler_step},\n",
    "    \"MnasNet_0-5\" : {\"model\" : models.mnasnet0_5(pretrained=True), \"type\" : \"cl\", \"epochs\" : num_epochs, \"lr_step\" : lr_scheduler_step},\n",
    "    \"Wide_ResNet_50-2\" : {\"model\" : models.wide_resnet50_2(pretrained=True), \"type\" : \"fc\", \"epochs\" : num_epochs, \"lr_step\" : lr_scheduler_step}\n",
    "#   ------------\n",
    "#     \"AlexNet\" : {\"model\" : models.alexnet(pretrained=True), \"type\" : \"cl\", \"epochs\" :int(num_epochs/2), \"lr_step\" : int(lr_scheduler_step / 2)},\n",
    "#     \"MobileNet_v2\" : {\"model\" : models.mobilenet_v2(pretrained=True), \"type\" : \"cl\", \"epochs\" : int(num_epochs/2), \"lr_step\" : int(lr_scheduler_step / 2)},\n",
    "#     \"ResNet_152\" : {\"model\" : models.resnet152(pretrained=True), \"type\" : \"fc\", \"epochs\" : int(num_epochs/3), \"lr_step\" : int(lr_scheduler_step / 2)},\n",
    "#     \"ResNeXt_101_32x8d\" : {\"model\" : models.resnext101_32x8d(pretrained=True), \"type\" : \"fc\", \"epochs\" : int(num_epochs/3), \"lr_step\" : int(lr_scheduler_step / 2)},\n",
    "#     \"Wide_ResNet_101-2\" : {\"model\" : models.wide_resnet101_2(pretrained=True), \"type\" : \"fc\", \"epochs\" : int(num_epochs/3), \"lr_step\" : int(lr_scheduler_step / 2)},\n",
    "#   ------------\n",
    "#     \"VGG_19_bn\" : {\"model\" : models.vgg19_bn(pretrained=True), \"type\" : \"cl\", \"epochs\" : num_epochs*2, \"lr_step\" : lr_scheduler_step * 2},\n",
    "#     \"MnasNet_1-0\" : {\"model\" : models.mnasnet1_0(pretrained=True), \"type\" : \"cl\", \"epochs\" : num_epochs*2, \"lr_step\" : lr_scheduler_step * 2},\n",
    "#     \"Inception_v3\" : {\"model\" : models.inception_v3(pretrained=True), \"type\" : \"fc\", \"epochs\" : num_epochs*2, \"lr_step\" : lr_scheduler_step * 2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IOQe4yeyoEaO"
   },
   "outputs": [],
   "source": [
    "def learn_model(model, model_name, params_to_learn, ep_num, lr_step):\n",
    "    mnl = int(len(model_name) / 2)\n",
    "    print(' ' * (40 - mnl), model_name, ' ' * (40 - mnl))\n",
    "    print('_'*80)\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(params_to_learn, lr=start_lr, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=lr_step, gamma=0.1) if use_lr_scheduler else None\n",
    "\n",
    "    model, learning_dict = train_model(model, criterion, optimizer, exp_lr_scheduler, ep_num)\n",
    "    \n",
    "    plot_learning_curve(learning_dict, model_name, True, save_path, save_dir)\n",
    "    \n",
    "    coeff_path = f\"{save_path}/{save_dir}/{model_name}.pth\"\n",
    "    torch.save(model.state_dict(), coeff_path)\n",
    "    model_dict[model_name][\"model\"] = model\n",
    "\n",
    "    score = test_model(model, False)\n",
    "    return convert_score_to_df({model_name : score}, True, save_path, save_dir, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "_r84iHxOJa25",
    "outputId": "08eeb879-8b70-4465-90a3-bff81c47301c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "                                 ResNeXt_50_32x4d                                 \n",
      "________________________________________________________________________________\n",
      "Начало обучения. Проход в 24 эпох.\n",
      "2020-01-27 01:21. Приблизительное оставшееся время 24м 42с\n",
      "***\n",
      " 5. train. loss: 0.8719. acc: 0.7447. time  0м 45с\n",
      " 5. valid. loss: 1.0264. acc: 0.7428. time  1м  1с\n"
     ]
    }
   ],
   "source": [
    "print('_'*80)\n",
    "for model_name in model_dict:\n",
    "    model = model_dict[model_name][\"model\"]\n",
    "    \n",
    "    if model_name == \"Inception_v3\":\n",
    "        data_transforms, image_datasets, dataloaders = update_data(paths, resize=340, center_crop=299, batch_size = batch_size)\n",
    "        model.aux_logits=False\n",
    "\n",
    "    # Указываем парамтры модели для которых не требуется строить граф вычислений градиента. <=> \"замораживаем веса\"\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    params_to_learn = model.parameters()\n",
    "\n",
    "    # Последний слой модели меняется на собственный полносвязный\n",
    "    if model_dict[model_name][\"type\"] == \"fc\":\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "        params_to_learn = model.fc.parameters()\n",
    "    else:\n",
    "        num_ftrs = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(num_ftrs, len(class_names))\n",
    "        params_to_learn = model.classifier[-1].parameters()\n",
    "    # Запуск процесса обновления весов\n",
    "    try:\n",
    "        learn_model(model, model_name, params_to_learn, model_dict[model_name][\"epochs\"], model_dict[model_name][\"lr_step\"])\n",
    "    except Exception as e:\n",
    "        print(f\"{model_name} failed. {str(e)}\")\n",
    "    print('_'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JK8O_PhIjmwh"
   },
   "source": [
    "## Объединение результатов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYOKkDf0jrcM"
   },
   "outputs": [],
   "source": [
    "def collect_stat(root=None):\n",
    "    if (root is not None) and os.path.isdir(root):\n",
    "        data = {}\n",
    "        for file_name in os.listdir(root):\n",
    "            if file_name.split('.')[-1] == \"csv\":\n",
    "                df = pd.read_csv(os.path.join(root, file_name), sep=';')\n",
    "                df = df.set_index(df.columns[0])\n",
    "#                 df = df.sort_values(by=[df.columns[0]])\n",
    "                \n",
    "                for col in df.columns:\n",
    "                    data[col] = df[col]\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_stat(f\"{save_path}/{save_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Точность ансамбля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_models = [\"ResNeXt_101_32x8d\",\"ResNet_152\", \"MnasNet_1-0\", \"MobileNet_v2\", \"Wide_ResNet_101-2\"]\n",
    "\n",
    "result_dict = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloaders[\"test\"]:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        for l in labels:\n",
    "            result_dict[\"real\"].append(l.item())\n",
    "            \n",
    "        for m_name in ans_models:\n",
    "            model = model_dict[m_name][\"model\"]\n",
    "            \n",
    "            if model_dict[m_name][\"type\"] == \"fc\":\n",
    "                model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
    "            else:\n",
    "                model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, len(class_names))\n",
    "            \n",
    "            model.load_state_dict(torch.load(f\"{save_path}/{save_dir}/{m_name}.pth\"))\n",
    "            \n",
    "            model = model.to(device)\n",
    "            \n",
    "            _, predicted = torch.max(model(images).data, 1)\n",
    "            for p in predicted:\n",
    "                result_dict[m_name].append(p.item())\n",
    "\n",
    "ans_df = pd.DataFrame(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(row):\n",
    "    cntr = Counter([ma for ma in row])\n",
    "    if len(cntr) == len(row):\n",
    "        #TODO переделать в наиболее вероятный\n",
    "        return row[\"ResNeXt_101_32x8d\"]\n",
    "    else:\n",
    "        return cntr.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_df[\"predicted\"] = ans_df[ans_models].apply(lambda row : summarize(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc = accuracy_score(ans_df[\"real\"], ans_df[\"predicted\"]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{total_acc :.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in ans_df[\"real\"].unique():\n",
    "    tmp = ans_df[ans_df[\"real\"] == cl]\n",
    "    acc = accuracy_score(tmp[\"real\"], tmp[\"predicted\"]) * 100\n",
    "    print(class_names[cl], f\"{acc :.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Все графики на одном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_plot(ax, data, m_name, mode, step):\n",
    "    epochs = data[\"train\"][\"epoch\"]\n",
    "    epcnt = float(epochs[-1])\n",
    "    for phase in [\"train\", \"valid\"]:\n",
    "#         clr = \"green\" if phase == \"valid\" else \"blue\"\n",
    "#         clr = \"light\" + clr if mode == \"acc\" else clr\n",
    "        ax.set_title(f\"{m_name}\", fontsize=12)\n",
    "        ax.plot(epochs, data[phase][mode], label=phase)\n",
    "        ax.set_ylabel(f\"{mode}\")\n",
    "        ax.legend(loc=1)\n",
    "        ax.grid(True)\n",
    "        delta = 0.001\n",
    "        ax.set_xlim(left=(0 - delta), right=(epcnt + delta))\n",
    "        ax.set_xticks([xt for xt in range(0, int(epcnt+2), step)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,4, figsize=(18,12))\n",
    "fig.tight_layout(h_pad=3, w_pad = 4)\n",
    "i = 0\n",
    "for file_name in os.listdir(f\"{save_path}/{save_dir}/\"):\n",
    "    if file_name.split('.')[-1] == \"json\":\n",
    "        path_json = f\"{save_path}/{save_dir}/{file_name}\"\n",
    "        data = json.load(open(path_json, 'r'))\n",
    "        model_name = file_name.split('.')[0]\n",
    "        pad = 0 if i < 4 else 1\n",
    "        single_plot(axs[int(i / 4) + pad][i % 4], data, model_name, \"loss\", 2)\n",
    "        single_plot(axs[int(i / 4) + pad+1][i % 4], data, model_name, \"acc\", 2)\n",
    "        i+=1\n",
    "plt.savefig(\"default_24ep.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XVMXHQMHXwtQ"
   },
   "source": [
    "## Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bQMhcHJ1XwtQ",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def predict(img_path=None, model_name=\"inception_v3\", path=\"/nn/default/inception_v3.pth\"):\n",
    "    if os.path.isfile(img_path) and (model_name in model_dict) and os.path.isfile(img_path):\n",
    "        img = Image.open(img_path)\n",
    "        model = model_dict[model_name]\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, 8)\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        model.eval()\n",
    "        \n",
    "        img_input = transforms.Compose(data_transforms[\"test\"])(img)\n",
    "        img_input = img_input.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = model(img_input)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            proba = torch.nn.functional.softmax(output, dim=1).tolist()[0]\n",
    "            \n",
    "            plt.barh(class_names, proba, align=\"center\")\n",
    "            plt.xlim(0, 1)\n",
    "            plt.xticks(np.arange(0, 1, 0.1))\n",
    "            plt.grid(True, axis=\"x\")\n",
    "            \n",
    "            for i, p in enumerate(proba):\n",
    "                print(f\"{p : .10f} - {class_names[i]}\")\n",
    "                plt.text(p, i, f\"{p : .10f}\")\n",
    "        return class_names[predicted[0]]\n",
    "    else:\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Trained_CNN_no_changes_in_data.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
